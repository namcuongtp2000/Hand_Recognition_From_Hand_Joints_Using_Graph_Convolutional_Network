{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TechVidvan Human pose estimator\n",
    "# import necessary packages\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# initialize Pose estimator\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# create capture object\n",
    "cap = cv2.VideoCapture('D:\\\\NGHIEN-CUU-COMVIS\\\\Picture\\\\20211217_102817.mp4')\n",
    "while cap.isOpened():\n",
    "    # read frame from capture object\n",
    "    _, frame = cap.read()\n",
    "    try:\n",
    "        # convert the frame to RGB format\n",
    "        RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # process the RGB frame to get the result\n",
    "        results = pose.process(RGB)\n",
    "        print(results.pose_landmarks)\n",
    "        # draw detected skeleton on the frame\n",
    "        mp_drawing.draw_landmarks(\n",
    "        frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        # show the final output\n",
    "        cv2.imshow('Output', frame)\n",
    "    except:\n",
    "        break\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
